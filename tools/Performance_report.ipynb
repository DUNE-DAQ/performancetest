{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "237e1111",
   "metadata": {},
   "source": [
    "# Notebook for the performance test report \n",
    "This Python code is used to generate a performance report PDF from PCM/uprof monitoring data collected during readout application tests.\n",
    "\n",
    "The key functions are:\n",
    "* plot_vars_comparison(): Plots performance metrics from PCM/uprof data for multiple tests into comparison plots. It generates a plot for each socket.\n",
    "* create_report_performance(): Creates the full PDF report.\n",
    "* Processes the raw PCM/uprof data if needed\n",
    "    * Generates the comparison plots by calling plot_vars_comparison()\n",
    "    * Adds intro text, table of tests, and the plots to the PDF\n",
    "    * Prints CPU core pinning info for each test\n",
    "    * It takes input data from a specified folder, processes it, generates plots in an output folder, and builds the PDF report with custom text, table, and plots.\n",
    "    \n",
    "Helper functions all bdefined in basic_functions.py:\n",
    "\n",
    "* make_name_list(): Generates lists of file names in the input folder\n",
    "* break_file_name(): Parses info from a file name\n",
    "* add_new_time_format(): Adds a timestamp column to PCM/uprof data\n",
    "* uprof_pcm_formatter(): Converts uprof data to PCM-like format\n",
    "* json_info(): Prints CPU pinning info for a test\n",
    "\n",
    "So in summary, it automates generating a performance report from raw monitoring data, including custom intro text, test info table, comparison plots, and configuration details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfdfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules needed, defining paths and functions\n",
    "from basic_functions import *\n",
    "\n",
    "print('Cheking list of packages need it')\n",
    "for package_i in list_py_package:\n",
    "    debug_missing_module(module_name=package_i)\n",
    "\n",
    "pcm_columns_list_0 = ['C0 Core C-state residency', 'Socket0 Memory Bandwidth',\n",
    "                      'Socket0 Instructions Per Cycle', 'Socket0 Instructions Retired Any (Million)',\n",
    "                      'Socket0 L2 Cache Misses', 'Socket0 L2 Cache Hits',\n",
    "                      'Socket0 L3 Cache Misses', 'Socket0 L3 Cache Hits']\n",
    "pcm_columns_list_1 = ['C0 Core C-state residency','Socket1 Memory Bandwidth',\n",
    "                      'Socket1 Instructions Per Cycle', 'Socket1 Instructions Retired Any (Million)', \n",
    "                      'Socket1 L2 Cache Misses', 'Socket1 L2 Cache Hits',\n",
    "                      'Socket1 L3 Cache Misses', 'Socket1 L3 Cache Hits']\n",
    "uprof_columns_list_0 = [' Utilization (%) Socket0', 'Total Mem Bw (GB/s) Socket0', \n",
    "                        'IPC (Sys + User) Socket0', ' ', \n",
    "                        'L2 Miss (pti) Socket0', 'L2 Access (pti) Socket0',\n",
    "                        'L3 Miss Socket0', 'L3 Miss % Socket0']\n",
    "uprof_columns_list_1 = ['Utilization (%) Socket1', 'Total Mem Bw (GB/s) Socket1', \n",
    "                        'IPC (Sys + User) Socket1', ' ',\n",
    "                        'L2 Miss (pti) Socket1', 'L2 Access (pti) Socket1',\n",
    "                        'L3 Miss Socket1', 'L3 Miss % Socket1']\n",
    "label_names = ['CPU Utilization (%)', 'Memory Bandwidth (GB/sec)', \n",
    "               'Instructions Per Cycle', 'Instructions Retired Any (Million)',\n",
    "               'L2 Cache Misses (Million)', 'L2 Cache [Misses/Accesses] (%)',\n",
    "               'L3 Cache Misses (Million)', 'L3 Cache [Misses/Accesses] (%)']\n",
    "label_columns = ['Socket0', 'Socket1']\n",
    "\n",
    "def plot_vars_comparison(input_dir, output_dir, pdf_name):\n",
    "    X_plot, Y_plot_0, Y_plot_1, label_plot_0, label_plot_1 = [], [], [], [], []\n",
    "    \n",
    "    pcm_file, uprof_file, core_utilization_file, reformated_uprof_file, reformated_core_utilization_file, all_file, all_plots_file = make_name_list(input_dir)\n",
    "    \n",
    "    for i, file_i in enumerate(all_plots_file):    \n",
    "        info = break_file_name(file_i)\n",
    "        data_frame = pd.read_csv('{}/{}.csv'.format(input_dir, file_i))\n",
    "        X_plot.append(data_frame['NewTime'].values.tolist())\n",
    "                \n",
    "        Y_tmp_0, Y_tmp_1, label_tmp_0, label_tmp_1 = [], [], [], []\n",
    "        \n",
    "        if info[0]=='grafana':\n",
    "            for k, (columns_pcm_0, columns_pcm_1) in enumerate(zip(pcm_columns_list_0, pcm_columns_list_1)):\n",
    "                Y_0, label_0 = get_column_val(data_frame, [columns_pcm_0], [label_columns[0]], file_i)  \n",
    "                Y_1, label_1 = get_column_val(data_frame, [columns_pcm_1], [label_columns[1]], file_i)  \n",
    "                Y_tmp_0.append(Y_0)\n",
    "                label_tmp_0.append(label_0)\n",
    "                Y_tmp_1.append(Y_1)\n",
    "                label_tmp_1.append(label_1)\n",
    "        else:\n",
    "            for k, (columns_uprof_0, columns_uprof_1) in enumerate(zip(uprof_columns_list_0, uprof_columns_list_1)):\n",
    "                Y_0, label_0 = get_column_val(data_frame, [columns_uprof_0], [label_columns[0]], file_i)\n",
    "                Y_1, label_1 = get_column_val(data_frame, [columns_uprof_1], [label_columns[1]], file_i)\n",
    "                Y_tmp_0.append(Y_0)\n",
    "                label_tmp_0.append(label_0)\n",
    "                Y_tmp_1.append(Y_1)\n",
    "                label_tmp_1.append(label_1)\n",
    "    \n",
    "        Y_plot_0.append(Y_tmp_0)\n",
    "        label_plot_0.append(label_tmp_0)\n",
    "        Y_plot_1.append(Y_tmp_1)\n",
    "        label_plot_1.append(label_tmp_1)\n",
    "    \n",
    "    # Here we make the plot:\n",
    "    matplotlib.rcParams['font.family'] = 'DejaVu Serif'\n",
    "    rows=cols=2\n",
    "    rows_cols = rows*cols\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(18, 8))\n",
    "    plt.style.use('default')\n",
    "    axs = axs.flatten()\n",
    "    #axs[3].axis('off')\n",
    "    \n",
    "    for i in range(len(Y_plot_0)):  #number of files or tests\n",
    "        for j in range(len(Y_plot_0[i])):  #number of metrix\n",
    "            if j < rows_cols:\n",
    "                label0_ij0 = re.sub('_', ' ', label_plot_0[i][j][0])\n",
    "                axs[j].plot(X_plot[i], Y_plot_0[i][j][0], color=color_list[i], label=label0_ij0, linestyle=linestyle_list[0])\n",
    "                axs[j].set_ylabel('{}'.format(label_names[j]))\n",
    "                axs[j].set_xlabel('Time (min)')\n",
    "                axs[j].grid(which='major', color='gray', linestyle='dashed')\n",
    "                axs[j].legend(loc='upper left')\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{}/{}_results_{}_socket0.png'.format(output_dir, pdf_name, info[4]))\n",
    "    print('{}/{}_results_{}_socket0.png'.format(output_dir, pdf_name, info[4]))\n",
    "    plt.close() \n",
    "    \n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(18, 8))\n",
    "    plt.style.use('default')\n",
    "    axs = axs.flatten()   \n",
    "    \n",
    "    for i in range(len(Y_plot_0)):  \n",
    "        for j in range(len(Y_plot_0[i])):\n",
    "            if j < rows_cols:\n",
    "                pass\n",
    "            else:\n",
    "                label0_ij0 = re.sub('_', ' ', label_plot_0[i][j][0])\n",
    "                axs[j-rows_cols].plot(X_plot[i], Y_plot_0[i][j][0], color=color_list[i], label=label0_ij0, linestyle=linestyle_list[0])\n",
    "                axs[j-rows_cols].set_ylabel('{}'.format(label_names[j]))\n",
    "                axs[j-rows_cols].set_xlabel('Time (min)')\n",
    "                axs[j-rows_cols].grid(which='major', color='gray', linestyle='dashed')\n",
    "                axs[j-rows_cols].legend(loc='upper left')\n",
    "                \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{}/{}_results_cache_{}_socket0.png'.format(output_dir, pdf_name, info[4]))\n",
    "    print('{}/{}_results_cache_{}_socket0.png'.format(output_dir, pdf_name, info[4]))\n",
    "    plt.close() \n",
    "    \n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(18, 8))\n",
    "    plt.style.use('default')\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i in range(len(Y_plot_1)):  \n",
    "        for j in range(len(Y_plot_1[i])):\n",
    "            if j < rows_cols:\n",
    "                label1_ij0 = re.sub('_', ' ', label_plot_1[i][j][0])\n",
    "                axs[j].plot(X_plot[i], Y_plot_1[i][j][0], color=color_list[i], label=label1_ij0, linestyle=linestyle_list[0])\n",
    "                axs[j].set_ylabel('{}'.format(label_names[j]))\n",
    "                axs[j].set_xlabel('Time (min)')\n",
    "                axs[j].grid(which='major', color='gray', linestyle='dashed')\n",
    "                axs[j].legend(loc='upper left')\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{}/{}_results_{}_socket1.png'.format(output_dir, pdf_name, info[4]))\n",
    "    print('{}/{}_results_{}_socket1.png'.format(output_dir, pdf_name, info[4]))\n",
    "    plt.close() \n",
    "    \n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(18, 8))\n",
    "    plt.style.use('default')\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i in range(len(Y_plot_1)):  \n",
    "        for j in range(len(Y_plot_1[i])):\n",
    "            if j < rows_cols:\n",
    "                pass\n",
    "            else:\n",
    "                label1_ij0 = re.sub('_', ' ', label_plot_1[i][j][0])\n",
    "                axs[j-rows_cols].plot(X_plot[i], Y_plot_1[i][j][0], color=color_list[i], label=label1_ij0, linestyle=linestyle_list[0])\n",
    "                axs[j-rows_cols].set_ylabel('{}'.format(label_names[j]))\n",
    "                axs[j-rows_cols].set_xlabel('Time (min)')\n",
    "                axs[j-rows_cols].grid(which='major', color='gray', linestyle='dashed')\n",
    "                axs[j-rows_cols].legend(loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{}/{}_results_cache_{}_socket1.png'.format(output_dir, pdf_name, info[4]))\n",
    "    print('{}/{}_results_cache_{}_socket1.png'.format(output_dir, pdf_name, info[4]))\n",
    "    plt.close() \n",
    "    \n",
    "def create_report_performance(input_dir, output_dir, daqconfs_cpupins_folder_parent_dir, process_pcm_files=False, process_uprof_files=False, print_info=True, streams='8, 16, 24, 32, 40, and 48', pdf_name='performance_report', repin_threads_file=None, comment=['TBA']):    \n",
    "    directory([input_dir, output_dir])\n",
    "    pcm_file, uprof_file, core_utilization_file, reformated_uprof_file, reformated_core_utilization_file, all_file, all_plots_file = make_name_list(input_dir)\n",
    "    \n",
    "    # Open pdf file\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.ln(1)\n",
    "    pdf.image('{}/tools/dune_logo_3.jpg'.format(performancetest_path), w=180)\n",
    "    pdf.ln(2)\n",
    "    pdf.set_font('Times', 'B', 16)\n",
    "    pdf.cell(40,10,'Performance Report')\n",
    "    pdf.ln(10)\n",
    "    \n",
    "    # Processing the data first\n",
    "    if process_pcm_files:\n",
    "        for i, file_pcm_i in enumerate(pcm_file):\n",
    "            add_new_time_format(input_dir, file_pcm_i)\n",
    "\n",
    "    if process_uprof_files:\n",
    "        for i, file_uprof_i in enumerate(uprof_file):\n",
    "            uprof_pcm_formatter(input_dir, file_uprof_i)\n",
    "            add_new_time_format(input_dir, 'reformatter_{}'.format(file_uprof_i))\n",
    "    \n",
    "    cpupins_utilazation_reformatter(input_dir)\n",
    "    for i, file_core_i in enumerate(core_utilization_file):\n",
    "         add_new_time_format_utilization(input_dir, 'reformatter_{}'.format(file_core_i))\n",
    "        \n",
    "    if process_pcm_files or process_uprof_files:\n",
    "        print('Finish the processing of the data.')\n",
    "    \n",
    "    print(all_file[0])\n",
    "    info_pcm_basic = break_file_name(all_file[0])\n",
    "    \n",
    "    # creating report\n",
    "    pdf.set_font('Times', '', 10)\n",
    "    pdf.write(5, 'The tests were run for the WIB{} data format for {} streams. The Figures 1 and 2 show the results of the tests ran (Table1) using the different metrics. \\n'.format(info_pcm_basic[4], streams))\n",
    "    pdf.write(5, '    * L2-hits is the fraction of requests that make it to L2 at all. Similar for L3. \\n')\n",
    "    pdf.write(5, '    * L2-misses is the fraction of requests that make it to L2 at all and then miss in L2. Similar for L3. \\n')\n",
    "    pdf.ln(10)\n",
    "    \n",
    "    #-------------------------------------------TABLE-----------------------------------------------\n",
    "    # Data to tabular\n",
    "    rows_data = []\n",
    "    headers = ['Test', 'Readout SRV', 'dunedaq', 'OS', 'NODE', 'General comments']\n",
    "    rows_data.append(headers)\n",
    "    \n",
    "    line_height = pdf.font_size * 2\n",
    "    col_width = [pdf.epw/3.8, pdf.epw/8, pdf.epw/7, pdf.epw/12, pdf.epw/12, pdf.epw/5]  \n",
    "    lh_list = [] #list with proper line_height for each row\n",
    "    \n",
    "    for i, file_i in enumerate(all_file):\n",
    "        info = break_file_name(file_i)\n",
    "        test_info = re.sub('_', ' ', info[5])\n",
    "        line = [test_info, info[2], info[1], check_OS(info[2]), info[3], comment[i]]\n",
    "        rows_data.append(line)\n",
    "    \n",
    "    # Determine line heights based on the number of words in each cell\n",
    "    for row in rows_data:\n",
    "        max_lines = 1  # Initialize with a minimum of 1 line\n",
    "        for datum in row:\n",
    "            lines_needed = len(str(datum).split('\\n'))  # Count the number of lines\n",
    "            max_lines = max(max_lines, lines_needed)\n",
    " \n",
    "        lh_list.append(line_height * max_lines)\n",
    "        \n",
    "    # Add table rows with word wrapping and dynamic line heights\n",
    "    for j, row in enumerate(rows_data):\n",
    "        line_height_table = lh_list[j] \n",
    "        for k, datum in enumerate(row):\n",
    "            pdf.multi_cell(col_width[k], line_height_table, datum, border=1, align='L', new_x=XPos.RIGHT, new_y=YPos.TOP, max_line_height=pdf.font_size)\n",
    "            \n",
    "        pdf.ln(line_height_table)\n",
    "        \n",
    "    pdf.write(5, 'Table 1. Summary of the tests ran. \\n')    \n",
    "    pdf.ln(10)\n",
    "    \n",
    "    #--------------------------------------------FIGURES------------------------------------------------\n",
    "    plot_vars_comparison(input_dir, output_dir, pdf_name)\n",
    "    \n",
    "    if info[3] == '0' or info[3] == '01':\n",
    "        pdf.image('{}/{}_results_{}_socket0.png'.format(output_dir, pdf_name, info_pcm_basic[4]), w=180)\n",
    "        pdf.write(5, 'Figure 1. Socket0 results of the tests ran using the metrics CPU Utilization (%), Memory Bandwidth (GB/sec), Instructions Per Cycle, Instructions Retired Any (Million).')\n",
    "        pdf.ln(10)\n",
    "        pdf.image('{}/{}_results_cache_{}_socket0.png'.format(output_dir, pdf_name, info_pcm_basic[4]), w=180)\n",
    "        pdf.write(5, 'Figure 2. Socket0 results of the tests ran using the metrics L2 Cache Misses (Million), L2 Cache [Misses/Hits] (%), L3 Cache Misses (Million), and L3 Cache [Misses/Hits] (%).')\n",
    "        pdf.ln(10)\n",
    "        \n",
    "        if info[3] == '01':\n",
    "            pdf.image('{}/{}_results_{}_socket1.png'.format(output_dir, pdf_name, info_pcm_basic[4]), w=180)\n",
    "            pdf.write(5, 'Figure 3. Socket1 results of the tests ran using the metrics CPU Utilization (%), Memory Bandwidth (GB/sec), Instructions Per Cycle, Instructions Retired Any (Million).')\n",
    "            pdf.ln(10)\n",
    "            pdf.image('{}/{}_results_cache_{}_socket1.png'.format(output_dir, pdf_name, info_pcm_basic[4]), w=180)\n",
    "            pdf.write(5, 'Figure 4. Socket1 results of the tests ran using the metrics L2 Cache Misses (Million), L2 Cache [Misses/Hits] (%), L3 Cache Misses (Million), and L3 Cache [Misses/Hits] (%).')\n",
    "            pdf.ln(10)\n",
    "        \n",
    "    if info[3] == '1':\n",
    "        pdf.image('{}/{}_results_{}_socket1.png'.format(output_dir, pdf_name, info_pcm_basic[4]), w=180)\n",
    "        pdf.write(5, 'Figure 1. Socket1 results of the tests ran using the metrics CPU Utilization (%), Memory Bandwidth (GB/sec), Instructions Per Cycle, Instructions Retired Any (Million).')\n",
    "        pdf.ln(10)\n",
    "        pdf.image('{}/{}_results_cache_{}_socket1.png'.format(output_dir, pdf_name, info_pcm_basic[4]), w=180)\n",
    "        pdf.write(5, 'Figure 2. Socket1 results of the tests ran using the metrics L2 Cache Misses (Million), L2 Cache [Misses/Hits] (%), L3 Cache Misses (Million), and L3 Cache [Misses/Hits] (%).')\n",
    "        pdf.ln(10)\n",
    "        \n",
    "    #----------------------------------------CONFIGURATIONS---------------------------------------------\n",
    "    pcm_file, uprof_file, core_utilization_file, reformated_uprof_file, reformated_core_utilization_file, all_file, all_plots_file = make_name_list(input_dir)\n",
    "    \n",
    "    if print_info:\n",
    "        pdf.write(5, 'Configurations: \\n', 'B')\n",
    "        for i in range(len(all_file)):\n",
    "            info = break_file_name(all_file[i])\n",
    "            \n",
    "            var_i='ru{}{}{}'.format(info[2], info[4], '0')\n",
    "            file_daqconf_i='daqconf-{}-{}-{}-{}'.format(info[4], info[5], info[2], info[3])\n",
    "            file_core_i='reformatter_core_utilization-{}-{}-{}-{}-{}'.format(info[1], info[2], info[3], info[4], info[5])\n",
    "            \n",
    "            if os.path.exists('{}/{}'.format(input_dir,file_core_i)):\n",
    "                json_info(file_daqconf=file_daqconf_i, file_core=file_core_i, input_directory=daqconfs_cpupins_folder_parent_dir, input_dir=input_dir, var=var_i, pdf=pdf, if_pdf=print_info, repin_threads_file=repin_threads_file[i])\n",
    "            else:\n",
    "                print('Missing {}'.format(file_core_i))\n",
    "                json_info(file_daqconf=file_daqconf_i, file_core='reformatter_core_utilization-all0', input_directory=daqconfs_cpupins_folder_parent_dir, input_dir='{}/tools'.format(daqconfs_cpupins_folder_parent_dir), var=var_i, pdf=pdf, if_pdf=print_info, repin_threads_file=repin_threads_file[i])\n",
    "            pdf.cell(0, 10, 'Table {}. CPU core pins information for the \"{}\" test using dune_daq {}.'.format(i+2, info[5], info[1]))\n",
    "            pdf.ln(10)           \n",
    "            \n",
    "    pdf.ln(20)\n",
    "    pdf.set_font('Times', '', 10)\n",
    "    pdf.write(5, 'The End, made on {}'.format(current_time()))\n",
    "    pdf.output('{}/{}_report.pdf'.format(output_dir, pdf_name))\n",
    "    \n",
    "    print('The report was create and saved to {}/{}.pdf'.format(output_dir, pdf_name))\n",
    "    \n",
    "print('Ready to run and process')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578984c4",
   "metadata": {},
   "source": [
    "## Proccesing data from Grafana\n",
    "To extract the data from a given dashboard in grafana (Note: change the paths to fit yours): \n",
    "* extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time, host, partition, input_dir, output_csv_file)\n",
    "* 'grafana_url' is:\n",
    "    * 'http://np04-srv-009.cern.ch:3000'  (legacy)\n",
    "    * 'http://np04-srv-017.cern.ch:31023' (new) \n",
    "* 'dashboard_uid' is the unic dashboard identifiyer, you can find this information on the link of the dashboard. The dashboard_uid code is in the web link after/d/.../ \n",
    "    * for intel-r-performance-counter-monitor-intel-r-pcm dashboard dashboard_uid = '91zWmJEVk'\n",
    "    * for daq-overview dashboard dashboard_uid = 'v4_3_0-overview'\n",
    "    * for frontend-ethernet dashboard dashboard_uid = 'v4_3_0-frontend_ethernet'\n",
    "* delta_time is [start, end] given in the format '%Y-%m-%d %H:%M:%S'\n",
    "* partition in some cases you will need to provide the partition name where the test was ran, for example \"np04hddev\"\n",
    "* host is the name of the server in study, for example: \"np02-srv-003\"     \n",
    "* output_csv_file (for performance tests): [version]-[server_app_tested]-[numa node]-[data format]-[tests_name]\n",
    "    * example of name: v4_1_1-np02srv003-0-eth-stream_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822201b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dvargas TPG adam tests\n",
    "\n",
    "grafana_url = 'http://np04-srv-009.cern.ch:3000'\n",
    "dashboard_uid = ['91zWmJEVk']\n",
    "host_used = ['np04-srv-021','np04-srv-022','np04-srv-028','np04-srv-029']\n",
    "\n",
    "delta_time_0 = [['2024-03-13 11:15:08', '2024-03-13 11:25:40'], \n",
    "                ['2024-03-13 10:47:52', '2024-03-13 10:55:30'], \n",
    "                ['2024-03-13 11:00:40', '2024-03-13 11:09:16']]\n",
    "\n",
    "delta_time_4 = [['2024-03-13 10:47:52', '2024-03-13 10:55:30'], \n",
    "                ['2024-03-13 10:47:52', '2024-03-13 10:55:30'], \n",
    "                ['2024-03-13 10:47:52', '2024-03-13 10:55:30'], \n",
    "                ['2024-03-13 10:47:52', '2024-03-13 10:55:30']]\n",
    "delta_time_5 = [['2024-03-13 11:15:08', '2024-03-13 11:25:40'], \n",
    "                ['2024-03-13 11:15:08', '2024-03-13 11:25:40'], \n",
    "                ['2024-03-13 11:15:08', '2024-03-13 11:25:40'], \n",
    "                ['2024-03-13 11:15:08', '2024-03-13 11:25:40']]\n",
    "delta_time_6 = [['2024-03-13 11:00:40', '2024-03-13 11:09:16'], \n",
    "                ['2024-03-13 11:00:40', '2024-03-13 11:09:16'], \n",
    "                ['2024-03-13 11:00:40', '2024-03-13 11:09:16'], \n",
    "                ['2024-03-13 11:00:40', '2024-03-13 11:09:16']]\n",
    "\n",
    "output_csv_file_0 = ['NFD_PROD4_240312-np04srv021-01-eth-SimpleThreshold', \n",
    "                     'NFD_PROD4_240312-np04srv021-01-eth-AbsRS', \n",
    "                     'NFD_PROD4_240312-np04srv021-01-eth-SilverBullet']\n",
    "output_csv_file_1 = ['NFD_PROD4_240312-np04srv022-01-eth-SimpleThreshold', \n",
    "                     'NFD_PROD4_240312-np04srv022-01-eth-AbsRS', \n",
    "                     'NFD_PROD4_240312-np04srv022-01-eth-SilverBullet']\n",
    "output_csv_file_2 = ['NFD_PROD4_240312-np04srv028-01-eth-SimpleThreshold', \n",
    "                     'NFD_PROD4_240312-np04srv028-01-eth-AbsRS', \n",
    "                     'NFD_PROD4_240312-np04srv028-01-eth-SilverBullet']\n",
    "output_csv_file_3 = ['NFD_PROD4_240312-np04srv029-01-eth-SimpleThreshold', \n",
    "                     'NFD_PROD4_240312-np04srv029-01-eth-AbsRS', \n",
    "                     'NFD_PROD4_240312-np04srv029-01-eth-SilverBullet']\n",
    "\n",
    "output_csv_file_4 = ['NFD_PROD4_240312-np04srv021-01-eth-AbsRS', \n",
    "                     'NFD_PROD4_240312-np04srv022-01-eth-AbsRS', \n",
    "                     'NFD_PROD4_240312-np04srv028-01-eth-AbsRS', \n",
    "                     'NFD_PROD4_240312-np04srv029-01-eth-AbsRS']\n",
    "output_csv_file_5 = ['NFD_PROD4_240312-np04srv021-01-eth-SimpleThreshold', \n",
    "                     'NFD_PROD4_240312-np04srv022-01-eth-SimpleThreshold', \n",
    "                     'NFD_PROD4_240312-np04srv028-01-eth-SimpleThreshold', \n",
    "                     'NFD_PROD4_240312-np04srv029-01-eth-SimpleThreshold']\n",
    "output_csv_file_6 = ['NFD_PROD4_240312-np04srv021-01-eth-SilverBullet', \n",
    "                     'NFD_PROD4_240312-np04srv022-01-eth-SilverBullet', \n",
    "                     'NFD_PROD4_240312-np04srv028-01-eth-SilverBullet', \n",
    "                     'NFD_PROD4_240312-np04srv029-01-eth-SilverBullet']\n",
    "\n",
    "delta_time0 = [delta_time_0, delta_time_0, delta_time_0, delta_time_0]\n",
    "output_csv_file0 = [output_csv_file_0, output_csv_file_1, output_csv_file_2, output_csv_file_3]\n",
    "results_path0 = ['/eos/home-d/dvargas/SWAN_projects/performance_results/np04srv021_tpg',\n",
    "                 '/eos/home-d/dvargas/SWAN_projects/performance_results/np04srv022_tpg',\n",
    "                 '/eos/home-d/dvargas/SWAN_projects/performance_results/np04srv028_tpg',\n",
    "                 '/eos/home-d/dvargas/SWAN_projects/performance_results/np04srv029_tpg']\n",
    "\n",
    "delta_time1 = [delta_time_4, delta_time_5, delta_time_6]\n",
    "output_csv_file1 = [output_csv_file_4, output_csv_file_5, output_csv_file_6]\n",
    "results_path1 = ['/eos/home-d/dvargas/SWAN_projects/performance_results/tpg_AbsRS_test',\n",
    "                 '/eos/home-d/dvargas/SWAN_projects/performance_results/tpg_SimpleThreshold_test',\n",
    "                 '/eos/home-d/dvargas/SWAN_projects/performance_results/tpg_SilverBullet_test']\n",
    "\n",
    "results_path_tpg = '/eos/home-d/dvargas/SWAN_projects/performance_results/adam_test_all'\n",
    "\n",
    "for host_i, output_csv_file_i, results_path_i, delta_time_i in zip(host_used, output_csv_file0, results_path0, delta_time0):\n",
    "    for output_csv_file_list, delta_time_list in zip(output_csv_file_i, delta_time_i):\n",
    "        extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time=delta_time_list, \n",
    "                                          host=host_i, partition=None, input_dir=results_path_i, \n",
    "                                          output_csv_file=output_csv_file_list)\n",
    "\n",
    "for output_csv_file_i, results_path_i, delta_time_i in zip(output_csv_file1, results_path1, delta_time1):\n",
    "    for host_i, output_csv_file_list, delta_time_list in zip(host_used, output_csv_file_i, delta_time_i):\n",
    "        extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time=delta_time_list, \n",
    "                                          host=host_i, partition=None, input_dir=results_path_i, \n",
    "                                          output_csv_file=output_csv_file_list)\n",
    "\n",
    "for host_i, output_csv_file_i in zip(host_used, output_csv_file0):\n",
    "    for output_csv_file_list, delta_time_list in zip(output_csv_file_i, delta_time_0):\n",
    "        extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time=delta_time_list, \n",
    "                                          host=host_i, partition=None, input_dir=results_path_tpg, \n",
    "                                          output_csv_file=output_csv_file_list)\n",
    "\n",
    "print('done :-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a8b09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test adding RX Missed Errors → Frontend Ethernet\n",
    "\n",
    "grafana_url = 'http://np04-srv-017.cern.ch:31023'\n",
    "dashboard_uid = ['v4_3_0-frontend_ethernet', 'v4_3_0-overview']\n",
    "partition = 'np04hddev'\n",
    "host_used = 'np04-srv-022'\n",
    "delta_time = [['2024-03-12 09:17:57', '2024-03-12 09:33:30'],\n",
    "              ['2024-03-12 09:17:57', '2024-03-12 09:33:30']]\n",
    "output_csv_file = ['v4_3_0-np04srv022-0-test0', 'v4_3_0-np04srv022-0-test1']\n",
    "results_path = ['/eos/home-d/dvargas/SWAN_projects/performance_results/np04srv022']\n",
    "\n",
    "for partition_list, delta_time_list, output_csv_file_list in zip(partition, delta_time, output_csv_file):\n",
    "    extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time=delta_time_list, \n",
    "                                      host=host_used, partition=partition_list, input_dir=results_path, \n",
    "                                      output_csv_file=output_csv_file_list)\n",
    "\n",
    "print('done :-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47749009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without raw recording\n",
    "\n",
    "grafana_url = 'http://np04-srv-009.cern.ch:3000'\n",
    "dashboard_uid = ['91zWmJEVk']\n",
    "host_used = 'np04-srv-022'\n",
    "partition = 'np04hddev'\n",
    "delta_time = [['2024-03-14 20:17:57', '2024-03-14 21:33:30'],\n",
    "              ['2024-03-14 16:24:47', '2024-03-14 16:40:36'],\n",
    "              ['2024-03-14 10:07:52', '2024-03-14 10:23:44']]\n",
    "output_csv_file = ['v4_3_0-np04srv022-0-k8s', 'v4_3_0-np04srv022-0-basic', 'v4_3_0-np04srv022-0-callbacks']\n",
    "results_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/np04srv022'\n",
    "\n",
    "for partition_list, delta_time_list, output_csv_file_list in zip(partition, delta_time, output_csv_file):\n",
    "    extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time=delta_time_list, \n",
    "                                      host=host_used, partition=None, input_dir=results_path, \n",
    "                                      output_csv_file=output_csv_file_list)\n",
    "\n",
    "print('done :-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a8c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without raw recording\n",
    "\n",
    "grafana_url = 'http://np04-srv-009.cern.ch:3000'\n",
    "dashboard_uid = ['91zWmJEVk']\n",
    "host_used = 'np02-srv-003'  \n",
    "delta_time = [['2023-11-28 12:59:32', '2023-11-28 14:11:36'],\n",
    "              ['2023-11-28 14:18:46', '2023-11-28 15:31:18']]\n",
    "output_csv_file = ['v4_2_1-np02srv003-0-eth-stream_scaling', \n",
    "                   'v4_2_1-np02srv003-0-eth-stream_scaling_swtpg']\n",
    "results_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/without_recording'\n",
    "\n",
    "for delta_time_list, output_csv_file_list in zip(delta_time, output_csv_file):\n",
    "    extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time=delta_time_list, \n",
    "                                      host=host_used, partition=None, input_dir=results_path, \n",
    "                                      output_csv_file=output_csv_file_list)\n",
    "\n",
    "print('done :-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1298b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with raw recording\n",
    "\n",
    "grafana_url = 'http://np04-srv-009.cern.ch:3000'\n",
    "dashboard_uid = ['91zWmJEVk']\n",
    "host_used = 'np02-srv-003'  \n",
    "delta_time = [['2023-11-28 15:38:44', '2023-11-28 16:50:50'],\n",
    "              ['2023-11-29 09:59:53', '2023-11-29 11:12:27']]\n",
    "output_csv_file = ['v4_2_0-np02srv003-0-eth-stream_scaling_recording', \n",
    "                   'v4_2_0-np02srv003-0-eth-stream_scaling_recording_swtpg']\n",
    "results_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/with_recording'\n",
    "\n",
    "for delta_time_list, output_csv_file_list in zip(delta_time, output_csv_file):\n",
    "    extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time=delta_time_list, \n",
    "                                      host=host_used, partition=None, input_dir=results_path, \n",
    "                                      output_csv_file=output_csv_file_list)\n",
    "\n",
    "print('done :-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea693364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mman spsc queue test app\n",
    "\n",
    "grafana_url = 'http://np04-srv-009.cern.ch:3000'\n",
    "dashboard_uid = ['91zWmJEVk']\n",
    "host_used = 'np02-srv-003'  \n",
    "delta_time = [['2024-01-25 13:57:17', '2024-01-25 14:04:27']]\n",
    "output_csv_file = ['v4_2_1-np02srv003-0-eth-queuetest_Intel']\n",
    "results_path = '/eos/user/m/mman/performancetest/tools/queuetest_results'\n",
    "\n",
    "for delta_time_list, output_csv_file_list in zip(delta_time, output_csv_file):\n",
    "    extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time=delta_time_list, \n",
    "                                      host=host_used, partition=None, input_dir=results_path, \n",
    "                                      output_csv_file=output_csv_file_list)\n",
    "\n",
    "print('done :-)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad15bb0",
   "metadata": {},
   "source": [
    "## Performance report\n",
    "To create the the performance report (Note: change the paths to fit yours): \n",
    "* create_report_performance(input_dir, output_dir, daqconfs_cpupins_folder_parent_dir, process_pcm_files=False, process_uprof_files=False, print_info=True, streams='8, 16, 24, 32, 40, and 48', pdf_name='performance_report', repin_threads_file=None, comment=['general comments about the run'])\n",
    "    * \n",
    "    * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc0bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## dvargas ---> TPG standalone reports\n",
    "\n",
    "results_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/adam_test_all'\n",
    "report_path = '/eos/home-d/dvargas/dunedaq_reports'\n",
    "performancetest_path='/eos/home-m/mman/performancetest'\n",
    "host_list = ['np04srv021','np04srv022','np04srv028','np04srv029']\n",
    "comments_all=[' ',' ',' ',' ',' ',' ',' ',' ',' ',' ',' ',' ']\n",
    "repin_threads_file='cpupin-absrs.json'\n",
    "\n",
    "create_report_performance(input_dir=results_path, output_dir=report_path, \n",
    "                          daqconfs_cpupins_folder_parent_dir=performancetest_path, \n",
    "                          process_pcm_files=True, process_uprof_files=True, \n",
    "                          print_info=False, streams='48', \n",
    "                          pdf_name='tpg_AbsRS_SilverBullet_SimpleThreshold', comment=comments_all,\n",
    "                          repin_threads_file=repin_threads_file)\n",
    "\n",
    "paths0 = ['/eos/home-d/dvargas/SWAN_projects/performance_results/np04srv021_tpg',\n",
    "         '/eos/home-d/dvargas/SWAN_projects/performance_results/np04srv022_tpg',\n",
    "         '/eos/home-d/dvargas/SWAN_projects/performance_results/np04srv028_tpg',\n",
    "         '/eos/home-d/dvargas/SWAN_projects/performance_results/np04srv029_tpg',\n",
    "         '/eos/home-d/dvargas/SWAN_projects/performance_results/tpg_AbsRS_test']\n",
    "names0 = ['np04srv021_tpg', 'np04srv022_tpg', 'np04srv028_tpg', 'np04srv029_tpg']\n",
    "comments0 = [['TBA', 'TBA', 'TBA'], ['TBA', 'TBA', 'TBA'], ['TBA', 'TBA', 'TBA'], ['TBA', 'TBA', 'TBA']]\n",
    "\n",
    "for list_path, list_name, list_comm in zip(paths0, names0, comments0):    \n",
    "    create_report_performance(input_dir=list_path, output_dir=report_path, \n",
    "                              daqconfs_cpupins_folder_parent_dir=performancetest_path, \n",
    "                              process_pcm_files=True, process_uprof_files=True, \n",
    "                              print_info=False, streams='48', pdf_name=list_name, \n",
    "                              comment=list_comm, repin_threads_file=repin_threads_file)\n",
    "\n",
    "paths1 = ['/eos/home-d/dvargas/SWAN_projects/performance_results/tpg_AbsRS_test',\n",
    "          '/eos/home-d/dvargas/SWAN_projects/performance_results/tpg_SimpleThreshold_test',\n",
    "          '/eos/home-d/dvargas/SWAN_projects/performance_results/tpg_SilverBullet_test']\n",
    "names1 = ['tpg_AbsRS_test', 'tpg_SimpleThreshold_test', 'tpg_SilverBullet_test', ]\n",
    "comments1 = [['TBA', 'TBA', 'TBA', 'TBA'], ['TBA', 'TBA', 'TBA', 'TBA'], ['TBA', 'TBA', 'TBA', 'TBA']]\n",
    "\n",
    "for list_path, list_name, list_comm in zip(paths1, names1, comments1):    \n",
    "    create_report_performance(input_dir=list_path, output_dir=report_path, \n",
    "                              daqconfs_cpupins_folder_parent_dir=performancetest_path, \n",
    "                              process_pcm_files=True, process_uprof_files=True, \n",
    "                              print_info=False, streams='48', pdf_name=list_name, \n",
    "                              comment=list_comm, repin_threads_file=repin_threads_file)\n",
    "\n",
    "print('THE END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515d9164",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## dvargas\n",
    "\n",
    "results_path_1 = '/eos/home-d/dvargas/SWAN_projects/performance_results/without_recording'\n",
    "results_path_2 = '/eos/home-d/dvargas/SWAN_projects/performance_results/with_recording'\n",
    "results_path_3 = '/eos/home-d/dvargas/SWAN_projects/performance_results/basic_stream_scaling_AMD'\n",
    "report_path = '/eos/home-d/dvargas/dunedaq_reports'\n",
    "performancetest_path = '/eos/home-d/dvargas/SWAN_projects/performancetest'\n",
    "\n",
    "paths = [results_path_1, results_path_2, results_path_3]\n",
    "names = ['performancetest_without_recording_np02srv004', 'performancetest_with_recording_np02srv004', 'performancetest_basic_stream_scaling_np02srv004_kernel_params']\n",
    "comments = [['TBA', 'TBA'], ['TBA', 'TBA'], ['Before new kernel params', 'After new kernel params']]\n",
    "\n",
    "for list_path, list_name, list_comm in zip(paths, names, comments):\n",
    "    create_report_performance(input_dir=list_path, output_dir=report_path, \n",
    "                              daqconfs_cpupins_folder_parent_dir=performancetest_path, \n",
    "                              process_pcm_files=False, process_uprof_files=False, \n",
    "                              print_info=True, streams='8, 16, 24, 32, 40, and 48', \n",
    "                              pdf_name=list_name, comment=list_comm)\n",
    "\n",
    "print('THE END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c688dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mman readout queue perftest\n",
    "results_path = '/eos/user/m/mman/performancetest/tools/queuetest_results'\n",
    "report_path = '/eos/home-d/dvargas/dunedaq_reports'\n",
    "performancetest_path = '/eos/user/m/mman/performancetest'\n",
    "\n",
    "create_report_performance(input_dir=results_path, output_dir=report_path, \n",
    "                          daqconfs_cpupins_folder_parent_dir=performancetest_path, \n",
    "                          process_pcm_files=True, process_uprof_files=True, \n",
    "                          print_info=True, streams='4', \n",
    "                          pdf_name='queuetest_AMD_debug',\n",
    "                          comment=['Unable to push within timeout period (timeout period was 0 milliseconds)', \n",
    "                                    'Unable to push within timeout period (timeout period was 0 milliseconds)'])\n",
    "\n",
    "print('THE END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ea029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6178fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27aa15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b0b1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
