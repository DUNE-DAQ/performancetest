{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad15bb0",
   "metadata": {},
   "source": [
    "# Notebook for the performance test report "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1efcb2",
   "metadata": {},
   "source": [
    "This Python code is used to generate a performance report PDF from PCM/uprof monitoring data collected during readout application tests.\n",
    "\n",
    "The key functions are:\n",
    "\n",
    "* plot_vars_comparison(): Plots performance metrics from PCM/uprof data for multiple tests into comparison plots. It generates a plot for each socket.\n",
    "\n",
    "* create_report_performance(): Creates the full PDF report. It:\n",
    "\n",
    "    * Processes the raw PCM/uprof data if needed\n",
    "    * Generates the comparison plots by calling plot_vars_comparison()\n",
    "    * Adds intro text, table of tests, and the plots to the PDF\n",
    "    * Prints CPU core pinning info for each test\n",
    "    * It takes input data from a specified folder, processes it, generates plots in an output folder, and builds the PDF report with custom text, table, and plots.\n",
    "\n",
    "How to run it:\n",
    "To extract the data from a given dashboard in grafana: \n",
    "* extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time, host, input_dir, output_csv_file)\n",
    "* 'grafana_url' is:\n",
    "    * 'http://np04-srv-009.cern.ch:3000'  (legacy)\n",
    "    * 'http://np04-srv-017.cern.ch:31023' (new) \n",
    "* 'dashboard_uid' is the unic dashboard identifiyer, you can find this information on the link of the dashboard. The dashboard_uid code is in the web link after/d/.../ \n",
    "    * for intel-r-performance-counter-monitor-intel-r-pcm dashboard dashboard_uid = '91zWmJEVk' \n",
    "* delta_time is [start, end] given in the format '%Y-%m-%d %H:%M:%S'\n",
    "* host is the name of the server in study for example: \"np02-srv-003\"     \n",
    "* output_csv_file (for performance tests): [version]-[server_app_tested]-[numa node]-[data format]-[tests_name]\n",
    "    * example of name: v4_1_1-np02srv003-0-eth-stream_scaling\n",
    "\n",
    "To create the the performance report: \n",
    "* create_report_performance(input_dir, output_dir, daqconfs_cpupins_folder_parent_dir, process_pcm_files=False, process_uprof_files=False, print_info=True, streams='8, 16, 24, 32, 40, and 48', pdf_name='performance_report', repin_threads_file=None, elog_message=['TBA'])\n",
    "    * \n",
    "    * \n",
    "\n",
    "Helper functions all bdefined in basic_functions.py:\n",
    "\n",
    "* make_name_list(): Generates lists of file names in the input folder\n",
    "* break_file_name(): Parses info from a file name\n",
    "* add_new_time_format(): Adds a timestamp column to PCM/uprof data\n",
    "* uprof_pcm_formatter(): Converts uprof data to PCM-like format\n",
    "* json_info(): Prints CPU pinning info for a test\n",
    "\n",
    "So in summary, it automates generating a performance report from raw monitoring data, including custom intro text, test info table, comparison plots, and configuration details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237e1111",
   "metadata": {},
   "source": [
    "### Import the modules needed, defining paths and funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22d8e991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cheking list of packages need it\n",
      "Ready to run and process\n"
     ]
    }
   ],
   "source": [
    "from basic_functions import *\n",
    "\n",
    "print('Cheking list of packages need it')\n",
    "for package_i in list_py_package:\n",
    "    debug_missing_module(module_name=package_i)\n",
    "\n",
    "pcm_columns_list_0 = ['C0 Core C-state residency', 'Socket0 Memory Bandwidth', 'Socket0 Instructions Per Cycle', \n",
    "                      'Socket0 L2 Cache Misses', 'Socket0 L2 Cache Hits', \n",
    "                      'Socket0 L3 Cache Misses', 'Socket0 L3 Cache Hits']\n",
    "\n",
    "pcm_columns_list_1 = ['C0 Core C-state residency', 'Socket1 Memory Bandwidth', 'Socket1 Instructions Per Cycle', \n",
    "                      'Socket1 L2 Cache Misses', 'Socket1 L2 Cache Hits', \n",
    "                      'Socket1 L3 Cache Misses', 'Socket1 L3 Cache Hits']\n",
    "\n",
    "uprof_columns_list_0 = [' Utilization (%) Socket0', 'Total Mem Bw (GB/s) Socket0', 'IPC (Sys + User) Socket0', \n",
    "                        'L2 Miss (pti) Socket0', 'L2 Access (pti) Socket0', \n",
    "                        'L3 Miss Socket0', 'L3 Miss % Socket0']\n",
    "\n",
    "uprof_columns_list_1 = ['Utilization (%) Socket1', 'Total Mem Bw (GB/s) Socket1', 'IPC (Sys + User) Socket1', \n",
    "                        'L2 Miss (pti) Socket1', 'L2 Access (pti) Socket1', \n",
    "                        'L3 Miss Socket1', 'L3 Miss % Socket1']\n",
    "\n",
    "label_names = ['CPU Utilization (%)', 'Memory Bandwidth (GB/sec)', 'Instructions Per Cycle', \n",
    "               'L2 Cache Misses (Million)', 'L2 Cache [Misses/Accesses] (%)', \n",
    "               'L3 Cache Misses (Million)', 'L3 Cache [Misses/Accesses] (%)']\n",
    "\n",
    "label_columns = ['Socket0', 'Socket1']    \n",
    "\n",
    "def plot_vars_comparison(input_dir, output_dir, pdf_name):\n",
    "    # Function to \n",
    "    X_plot, Y_plot_0, Y_plot_1, label_plot_0, label_plot_1 = [], [], [], [], []\n",
    "    \n",
    "    pcm_file, uprof_file, core_utilization_file, reformated_uprof_file, reformated_core_utilization_file, all_file, all_plots_file = make_name_list(input_dir)\n",
    "    \n",
    "    for i, file_i in enumerate(all_plots_file):    \n",
    "        info = break_file_name(file_i)\n",
    "        data_frame = pd.read_csv('{}/{}.csv'.format(input_dir, file_i))\n",
    "        X_plot.append(data_frame['NewTime'].values.tolist())\n",
    "                \n",
    "        Y_tmp_0, Y_tmp_1, label_tmp_0, label_tmp_1 = [], [], [], []\n",
    "        \n",
    "        if info[0]=='grafana':\n",
    "            for k, (columns_pcm_0, columns_pcm_1) in enumerate(zip(pcm_columns_list_0, pcm_columns_list_1)):\n",
    "                Y_0, label_0 = get_column_val(data_frame, [columns_pcm_0], [label_columns[0]], file_i)  \n",
    "                Y_1, label_1 = get_column_val(data_frame, [columns_pcm_1], [label_columns[1]], file_i)  \n",
    "                Y_tmp_0.append(Y_0)\n",
    "                label_tmp_0.append(label_0)\n",
    "                Y_tmp_1.append(Y_1)\n",
    "                label_tmp_1.append(label_1)\n",
    "        else:\n",
    "            for k, (columns_uprof_0, columns_uprof_1) in enumerate(zip(uprof_columns_list_0, uprof_columns_list_1)):\n",
    "                Y_0, label_0 = get_column_val(data_frame, [columns_uprof_0], [label_columns[0]], file_i)\n",
    "                Y_1, label_1 = get_column_val(data_frame, [columns_uprof_1], [label_columns[1]], file_i)\n",
    "                Y_tmp_0.append(Y_0)\n",
    "                label_tmp_0.append(label_0)\n",
    "                Y_tmp_1.append(Y_1)\n",
    "                label_tmp_1.append(label_1)\n",
    "    \n",
    "        Y_plot_0.append(Y_tmp_0)\n",
    "        label_plot_0.append(label_tmp_0)\n",
    "        Y_plot_1.append(Y_tmp_1)\n",
    "        label_plot_1.append(label_tmp_1)\n",
    "    \n",
    "    # Here we make the plot:\n",
    "    matplotlib.rcParams['font.family'] = 'DejaVu Serif'\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(18, 12))\n",
    "    plt.style.use('default')\n",
    "    axs = axs.flatten()\n",
    "    #axs[3].axis('off')\n",
    "    \n",
    "    for i in range(len(Y_plot_0)):  #number of files or tests\n",
    "        for j in range(len(Y_plot_0[i])):  #number of metrix\n",
    "            if j < 3:\n",
    "                label0_ij0 = re.sub('_', ' ', label_plot_0[i][j][0])\n",
    "                axs[j].plot(X_plot[i], Y_plot_0[i][j][0], color=color_list[i], label=label0_ij0, linestyle=linestyle_list[0])\n",
    "                axs[j].set_ylabel('{}'.format(label_names[j]))\n",
    "                axs[j].set_xlabel('Time (min)')\n",
    "                axs[j].grid(which='major', color='gray', linestyle='dashed')\n",
    "                axs[j].legend(loc='upper left')\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{}/{}_results_{}_{}_socket0.png'.format(output_dir, pdf_name, info[1], info[4]))\n",
    "    plt.close() \n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(18, 8))\n",
    "    plt.style.use('default')\n",
    "    axs = axs.flatten()   \n",
    "    \n",
    "    for i in range(len(Y_plot_0)):  \n",
    "        for j in range(len(Y_plot_0[i])):\n",
    "            if j < 3:\n",
    "                pass\n",
    "            else:\n",
    "                label0_ij0 = re.sub('_', ' ', label_plot_0[i][j][0])\n",
    "                axs[j-3].plot(X_plot[i], Y_plot_0[i][j][0], color=color_list[i], label=label0_ij0, linestyle=linestyle_list[0])\n",
    "                axs[j-3].set_ylabel('{}'.format(label_names[j]))\n",
    "                axs[j-3].set_xlabel('Time (min)')\n",
    "                axs[j-3].grid(which='major', color='gray', linestyle='dashed')\n",
    "                axs[j-3].legend(loc='upper left')\n",
    "                \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{}/{}_results_cache_{}_{}_socket0.png'.format(output_dir, pdf_name, info[1], info[4]))\n",
    "    plt.close() \n",
    "    \n",
    "    fig, axs = plt.subplots(3, 1, figsize=(18, 12))\n",
    "    plt.style.use('default')\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i in range(len(Y_plot_1)):  \n",
    "        for j in range(len(Y_plot_1[i])):\n",
    "            if j < 3:\n",
    "                label1_ij0 = re.sub('_', ' ', label_plot_1[i][j][0])\n",
    "                axs[j].plot(X_plot[i], Y_plot_1[i][j][0], color=color_list[i], label=label1_ij0, linestyle=linestyle_list[0])\n",
    "                axs[j].set_ylabel('{}'.format(label_names[j]))\n",
    "                axs[j].set_xlabel('Time (min)')\n",
    "                axs[j].grid(which='major', color='gray', linestyle='dashed')\n",
    "                axs[j].legend(loc='upper left')\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{}/{}_results_{}_{}_socket1.png'.format(output_dir, pdf_name, info[1], info[4]))\n",
    "    plt.close() \n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(18, 8))\n",
    "    plt.style.use('default')\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i in range(len(Y_plot_1)):  \n",
    "        for j in range(len(Y_plot_1[i])):\n",
    "            if j < 3:\n",
    "                pass\n",
    "            else:\n",
    "                label1_ij0 = re.sub('_', ' ', label_plot_1[i][j][0])\n",
    "                axs[j-3].plot(X_plot[i], Y_plot_1[i][j][0], color=color_list[i], label=label1_ij0, linestyle=linestyle_list[0])\n",
    "                axs[j-3].set_ylabel('{}'.format(label_names[j]))\n",
    "                axs[j-3].set_xlabel('Time (min)')\n",
    "                axs[j-3].grid(which='major', color='gray', linestyle='dashed')\n",
    "                axs[j-3].legend(loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{}/{}_results_cache_{}_{}_socket1.png'.format(output_dir, pdf_name, info[1], info[4]))\n",
    "    plt.close() \n",
    "\n",
    "def create_report_performance(input_dir, output_dir, daqconfs_cpupins_folder_parent_dir, process_pcm_files=False, process_uprof_files=False, print_info=True, streams='8, 16, 24, 32, 40, and 48', pdf_name='performance_report', repin_threads_file=None, elog_message=['TBA']):    \n",
    "    # Function to \n",
    "    directory([input_dir, output_dir])\n",
    "    pcm_file, uprof_file, core_utilization_file, reformated_uprof_file, reformated_core_utilization_file, all_file, all_plots_file = make_name_list(input_dir)\n",
    "    \n",
    "    # Open pdf file\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font('Times', 'B', 16)\n",
    "    pdf.cell(40,10,'Performance Report')\n",
    "    pdf.ln(10)\n",
    "    \n",
    "    # Processing the data first\n",
    "    if process_pcm_files:\n",
    "        for i, file_pcm_i in enumerate(pcm_file):\n",
    "            add_new_time_format(input_dir, file_pcm_i)\n",
    "\n",
    "    if process_uprof_files:\n",
    "        for i, file_uprof_i in enumerate(uprof_file):\n",
    "            uprof_pcm_formatter(input_dir, file_uprof_i)\n",
    "            add_new_time_format(input_dir, 'reformatter_{}'.format(file_uprof_i))\n",
    "    \n",
    "    cpupins_utilazation_reformatter(input_dir)\n",
    "    for i, file_core_i in enumerate(core_utilization_file):\n",
    "         add_new_time_format_utilization(input_dir, 'reformatter_{}'.format(file_core_i))\n",
    "        \n",
    "    if process_pcm_files or process_uprof_files:\n",
    "        print('Finish the processing of the data.')\n",
    "    \n",
    "    info_pcm_basic = break_file_name(all_file[0])\n",
    "    \n",
    "    # creating report\n",
    "    pdf.set_font('Times', '', 10)\n",
    "    pdf.write(5, 'The tests were run using the dunedaq version fddaq-{} and for the WIB{} data format for {} streams. The Figures 1 and 2 show the results of the tests ran (Table1) using the different metrics. \\n'.format(info_pcm_basic[1], info_pcm_basic[4], streams))\n",
    "    pdf.write(5, '    * L2-hits is the fraction of requests that make it to L2 at all. Similar for L3. \\n')\n",
    "    pdf.write(5, '    * L2-misses is the fraction of requests that make it to L2 at all and then miss in L2. Similar for L3. \\n')\n",
    "    pdf.ln(10)\n",
    "    \n",
    "    #-------------------------------------------TABLE-----------------------------------------------\n",
    "    # Data to tabular\n",
    "    rows_data = []\n",
    "    headers = ['Test', 'Readout app SRV', 'OS', 'NODE', 'Elog message']\n",
    "    rows_data.append(headers)\n",
    "    \n",
    "    line_height = pdf.font_size * 2\n",
    "    col_width = [pdf.epw/3.8, pdf.epw/6.8, pdf.epw/12, pdf.epw/12, pdf.epw/2.8]  \n",
    "    lh_list = [] #list with proper line_height for each row\n",
    "    \n",
    "    for i, file_i in enumerate(all_file):\n",
    "        info = break_file_name(file_i)\n",
    "        test_info = re.sub('_', ' ', info[5])\n",
    "        #line = [info[5], info[2], check_OS(info[2]), info[3], elog_message[i]]\n",
    "        line = [test_info, info[2], check_OS(info[2]), info[3], elog_message[i]]\n",
    "        rows_data.append(line)\n",
    "    \n",
    "    # Determine line heights based on the number of words in each cell\n",
    "    for row in rows_data:\n",
    "        max_lines = 1  # Initialize with a minimum of 1 line\n",
    "        for datum in row:\n",
    "            lines_needed = len(str(datum).split('\\n'))  # Count the number of lines\n",
    "            max_lines = max(max_lines, lines_needed)\n",
    " \n",
    "        lh_list.append(line_height * max_lines)\n",
    "        \n",
    "    # Add table rows with word wrapping and dynamic line heights\n",
    "    for j, row in enumerate(rows_data):\n",
    "        line_height_table = lh_list[j] \n",
    "        for k, datum in enumerate(row):\n",
    "            pdf.multi_cell(col_width[k], line_height_table, datum, border=1, align='L', new_x=XPos.RIGHT, new_y=YPos.TOP, max_line_height=pdf.font_size)\n",
    "            \n",
    "        pdf.ln(line_height_table)\n",
    "        \n",
    "    pdf.write(5, 'Table 1. Summary of the tests ran. \\n')    \n",
    "    pdf.ln(10)\n",
    "    \n",
    "    #--------------------------------------------FIGURES------------------------------------------------\n",
    "    plot_vars_comparison(input_dir, output_dir, pdf_name)\n",
    "    \n",
    "    if info[3] == '0' or info[3] == '2':\n",
    "        pdf.image('{}/{}_results_{}_{}_socket0.png'.format(output_dir, pdf_name, info_pcm_basic[1], info_pcm_basic[4]), w=180)\n",
    "        pdf.write(5, 'Figure 1. Socket0 results of the tests ran using the metrics CPU Utilization (%), Memory Bandwidth (GB/sec), Instructions Per Cycle.')\n",
    "        pdf.ln(10)\n",
    "        pdf.image('{}/{}_results_cache_{}_{}_socket0.png'.format(output_dir, pdf_name, info_pcm_basic[1], info_pcm_basic[4]), w=180)\n",
    "        pdf.write(5, 'Figure 2. Socket0 results of the tests ran using the metrics L2 Cache Misses (Million), L2 Cache [Misses/Hits] (%), L3 Cache Misses (Million), and L3 Cache [Misses/Hits] (%).')\n",
    "        pdf.ln(10)\n",
    "        \n",
    "    if info[3] == '1' or info[3] == '2':\n",
    "        pdf.image('{}/{}_results_{}_{}_socket1.png'.format(output_dir, pdf_name, info_pcm_basic[1], info_pcm_basic[4]), w=180)\n",
    "        pdf.write(5, 'Figure 1. Socket1 results of the tests ran using the metrics CPU Utilization (%), Memory Bandwidth (GB/sec), Instructions Per Cycle.')\n",
    "        pdf.ln(10)\n",
    "        pdf.image('{}/{}_results_cache_{}_{}_socket1.png'.format(output_dir, pdf_name, info_pcm_basic[1], info_pcm_basic[4]), w=180)\n",
    "        pdf.write(5, 'Figure 2. Socket1 results of the tests ran using the metrics L2 Cache Misses (Million), L2 Cache [Misses/Hits] (%), L3 Cache Misses (Million), and L3 Cache [Misses/Hits] (%).')\n",
    "        pdf.ln(10)\n",
    "    \n",
    "    #----------------------------------------CONFIGURATIONS---------------------------------------------\n",
    "    pcm_file, uprof_file, core_utilization_file, reformated_uprof_file, reformated_core_utilization_file, all_file, all_plots_file = make_name_list(input_dir)\n",
    "    \n",
    "    if print_info:\n",
    "        pdf.write(5, 'Configurations: \\n', 'B')\n",
    "        for i, (file_i, file_ii) in enumerate(zip(all_file, reformated_core_utilization_file)):\n",
    "            info = break_file_name(file_i)\n",
    "            file_daqconf_i='daqconf-{}-{}-{}-{}'.format(info[4], info[5], info[2], info[3])\n",
    "            var_i='ru{}{}{}'.format(info[2], info[4], '0')\n",
    "            json_info(file_daqconf=file_daqconf_i, file_core=file_ii, input_directory=daqconfs_cpupins_folder_parent_dir, input_dir=input_dir, var=var_i, pdf=pdf, if_pdf=print_info, repin_threads_file=repin_threads_file)\n",
    "            pdf.cell(0, 10, 'Table {}. CPU core pins information for the \"{}\" test.'.format(i+2, info[5]))\n",
    "            pdf.ln(10)\n",
    "            \n",
    "    pdf.ln(20)\n",
    "    pdf.set_font('Times', '', 10)\n",
    "    pdf.write(5, 'The End, made on {}'.format(current_time()))\n",
    "    pdf.output('{}/{}_report.pdf'.format(output_dir, pdf_name))\n",
    "    \n",
    "print('Ready to run and process')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578984c4",
   "metadata": {},
   "source": [
    "### Proccesing data from Grafana\n",
    "Note: change the paths to fit yours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a8c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without raw recording\n",
    "\n",
    "grafana_url = 'http://np04-srv-009.cern.ch:3000'\n",
    "dashboard_uid = ['91zWmJEVk']\n",
    "host_used = 'np02-srv-003'  \n",
    "delta_time = [['2023-11-28 12:59:32', '2023-11-28 14:11:36'],\n",
    "              ['2023-11-28 14:18:46', '2023-11-28 15:31:18']]\n",
    "output_csv_file = ['v4_2_1-np02srv003-0-eth-stream_scaling', \n",
    "                   'v4_2_1-np02srv003-0-eth-stream_scaling_swtpg']\n",
    "results_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/without_recording'\n",
    "\n",
    "for delta_time_list, output_csv_file_list in zip(delta_time, output_csv_file):\n",
    "    extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time=delta_time_list, host=host_used, \n",
    "                                      input_dir=results_path, output_csv_file=output_csv_file_list)\n",
    "\n",
    "print('done :-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1298b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with raw recording\n",
    "\n",
    "grafana_url = 'http://np04-srv-009.cern.ch:3000'\n",
    "dashboard_uid = ['91zWmJEVk']\n",
    "host_used = 'np02-srv-003'  \n",
    "delta_time = [['2023-11-28 15:38:44', '2023-11-28 16:50:50'],\n",
    "              ['2023-11-29 09:59:53', '2023-11-29 11:12:27']]\n",
    "output_csv_file = ['v4_2_0-np02srv003-0-eth-stream_scaling_recording', \n",
    "                   'v4_2_0-np02srv003-0-eth-stream_scaling_recording_swtpg']\n",
    "results_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/with_recording'\n",
    "\n",
    "for delta_time_list, output_csv_file_list in zip(delta_time, output_csv_file):\n",
    "    extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time=delta_time_list, host=host_used, \n",
    "                                      input_dir=results_path, output_csv_file=output_csv_file_list)\n",
    "\n",
    "print('done :-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ee3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just 48 stereams fro tpg tests\n",
    "\n",
    "grafana_url = 'http://np04-srv-009.cern.ch:3000'\n",
    "dashboard_uid = ['91zWmJEVk']\n",
    "host_used = 'np02-srv-003'  \n",
    "tpg_delta_time = [['2023-11-23 18:41:24', '2023-11-23 18:56:32'],\n",
    "                  ['2023-11-23 18:58:48', '2023-11-23 19:13:56'],\n",
    "                  ['2023-11-24 13:15:46', '2023-11-24 13:30:54'],\n",
    "                  ['2023-11-24 13:55:35', '2023-11-24 14:10:44'],\n",
    "                  ['2023-11-24 11:55:41', '2023-11-24 12:10:50'],\n",
    "                  ['2023-11-24 12:13:48', '2023-11-24 12:28:56']]\n",
    "tpg_output_csv_file = ['v4_2_0-np02srv003-0-eth-48streams_swtpg', \n",
    "                       'v4_2_0-np02srv003-1-eth-48streams_swtpg', \n",
    "                       'v4_2_0-np02srv003-0-eth-48streams_recording_swtpg',\n",
    "                       'v4_2_0-np02srv003-1-eth-48streams_recording_swtpg',\n",
    "                       'v4_2_0-np02srv003-1-eth-48streams_recording_swtpg_multinode',\n",
    "                       'v4_2_0-np02srv003-1-eth-48streams_recording_swtpg_multinode_notrigger']\n",
    "tpg_results_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/with_tpgs_intel'\n",
    "\n",
    "for delta_time_list, output_csv_file_list in zip(tpg_delta_time, tpg_output_csv_file):\n",
    "    extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time=delta_time_list, host=host_used, \n",
    "                                      input_dir=tpg_results_path, output_csv_file=output_csv_file_list)\n",
    "\n",
    "print('done :-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea693364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mman spsc queue test app\n",
    "\n",
    "grafana_url = 'http://np04-srv-009.cern.ch:3000'\n",
    "dashboard_uid = ['91zWmJEVk']\n",
    "host_used = 'np02-srv-003'  \n",
    "delta_time = [['2024-01-25 13:57:17', '2024-01-25 14:04:27']]\n",
    "output_csv_file = ['v4_2_1-np02srv003-0-eth-queuetest_Intel']\n",
    "results_path = '/eos/user/m/mman/performancetest/tools/queuetest_results'\n",
    "\n",
    "for delta_time_list, output_csv_file_list in zip(delta_time, output_csv_file):\n",
    "    extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time=delta_time_list, host=host_used, \n",
    "                                      input_dir=results_path, output_csv_file=output_csv_file_list)\n",
    "\n",
    "print('done :-)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60327afa",
   "metadata": {},
   "source": [
    "### Performance report\n",
    "Note: change the paths to fit yours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "515d9164",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New CSV file saved as: reformatter_core_utilization-v4_2_1-np02srv003-0-eth-stream_scaling.csv \n",
      "New CSV file saved as: reformatter_core_utilization-v4_2_1-np02srv003-0-eth-stream_scaling_swtpgs.csv \n",
      "Finish the processing of the data.\n",
      "THE END\n"
     ]
    }
   ],
   "source": [
    "results_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/without_recording'\n",
    "report_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/reports'\n",
    "performancetest_path = '/eos/home-d/dvargas/SWAN_projects/performancetest'\n",
    "\n",
    "create_report_performance(input_dir=results_path, output_dir=report_path, \n",
    "                          daqconfs_cpupins_folder_parent_dir=performancetest_path, \n",
    "                          process_pcm_files=True, process_uprof_files=True, \n",
    "                          print_info=True, streams='8, 16, 24, 32, 40, and 48', \n",
    "                          pdf_name='performancetest_without_recording', \n",
    "                          elog_message=['0.1 Hz', '0.1 Hz second'])\n",
    "\n",
    "print('THE END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c688dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mman readout queue perftest\n",
    "results_path = '/eos/user/m/mman/performancetest/tools/queuetest_results'\n",
    "report_path = '/eos/user/m/mman/performancetest/tools/performance_reports'\n",
    "performancetest_path = '/eos/user/m/mman/performancetest'\n",
    "\n",
    "create_report_performance(input_dir=results_path, output_dir=report_path, \n",
    "                          daqconfs_cpupins_folder_parent_dir=performancetest_path, \n",
    "                          process_pcm_files=True, process_uprof_files=True, \n",
    "                          print_info=True, streams='4', \n",
    "                          pdf_name='queuetest_AMD_debug',\n",
    "                          elog_message=['Unable to push within timeout period (timeout period was 0 milliseconds)', \n",
    "                                        'Unable to push within timeout period (timeout period was 0 milliseconds)'])\n",
    "\n",
    "print('THE END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9cdbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/with_recording'\n",
    "report_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/reports'\n",
    "performancetest_path = '/eos/home-d/dvargas/SWAN_projects/performancetest'\n",
    "\n",
    "create_report_performance(input_dir=results_path, output_dir=report_path, \n",
    "                          daqconfs_cpupins_folder_parent_dir=performancetest_path, \n",
    "                          process_pcm_files=True, process_uprof_files=True, \n",
    "                          print_info=True, streams='8, 16, 24, 32, 40, and 48', \n",
    "                          pdf_name='performancetest_with_recording_report',\n",
    "                          elog_message=['0.1 Hz', '0.1 Hz second'])\n",
    "\n",
    "print('THE END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance report for 48 streams only, to study the TPG rate problems in the intel\n",
    "\n",
    "tpg_results_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/with_tpgs_intel'\n",
    "report_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/reports'\n",
    "performancetest_path = '/eos/home-d/dvargas/SWAN_projects/performancetest'\n",
    "\n",
    "create_report_performance(input_dir=tpg_results_path, output_dir=report_path, \n",
    "                          daqconfs_cpupins_folder_parent_dir=performancetest_path, \n",
    "                          process_pcm_files=True, process_uprof_files=False, \n",
    "                          print_info=True, streams='48', pdf_name='performancetest_tpg_intel_report',\n",
    "                          elog_message=['0.1 Hz', '0.1 Hz second'])\n",
    "\n",
    "print('THE END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f20ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance report for 48 streams only, to study the TPG rate problems in the amd\n",
    "\n",
    "tpg_results_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/with_tpgs_amd'\n",
    "report_path = '/eos/home-d/dvargas/SWAN_projects/performance_results/reports'\n",
    "performancetest_path = '/eos/home-d/dvargas/SWAN_projects/performancetest'\n",
    "\n",
    "create_report_performance(input_dir=tpg_results_path, output_dir=report_path, \n",
    "                          daqconfs_cpupins_folder_parent_dir=performancetest_path, \n",
    "                          process_pcm_files=False, process_uprof_files=True, \n",
    "                          print_info=True, streams='48', pdf_name='performancetest_tpg_amd_report',\n",
    "                          elog_message=['0.1 Hz', '0.1 Hz second'])\n",
    "\n",
    "print('THE END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2504ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
