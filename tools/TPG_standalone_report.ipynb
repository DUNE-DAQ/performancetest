{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad15bb0",
   "metadata": {},
   "source": [
    "# Notebook for the TPG standalone test report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d8e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules needed, defining paths and funtions\n",
    "from basic_functions import *\n",
    "\n",
    "print('Cheking list od packages need it')\n",
    "for package_i in list_py_package:\n",
    "    debug_missing_module(module_name=package_i)\n",
    "\n",
    "columns_list_tpg = [['Socket0 Instructions Per Cycle', 'Socket0 Instructions Retired Any (Million)'], ['IPC (Sys + User) Socket0', ' ']]\n",
    "label_names_tpg = ['Instructions Per Cycle', 'Instructions Retired Any (Million)']\n",
    "tpg_test_list = ['tpg_SimpletTreshold_standalone', 'tpg_AbsRS_standalone']\n",
    "\n",
    "label_columns = ['Socket0', 'Socket1'] \n",
    "color_list = ['red', 'blue', 'green', 'cyan', 'orange', 'navy', 'magenta', 'lime', 'purple', 'hotpink', \n",
    "              'olive', 'salmon', 'teal', 'darkblue', 'darkgreen', 'darkcyan', 'darkorange', 'deepskyblue', \n",
    "              'darkmagenta', 'sienna', 'chocolate', 'orangered', 'gray', 'royalblue', 'gold', 'peru', \n",
    "              'seagreen', 'violet', 'tomato', 'lightsalmon', 'crimson', 'lightblue', 'lightgreen', \n",
    "              'lightpink', 'black', 'darkgray', 'lightgray', 'saddlebrown', 'brown', 'khaki', 'tan', \n",
    "              'turquoise', 'linen', 'lawngreen']\n",
    "linestyle_list = ['solid', 'dotted', 'dashed', 'dashdot','solid', 'dotted', 'dashed', 'dashdot']\n",
    "marker_list = ['s','o','.','p','P','^','<','>','*','+','x','X','d','D','h','H']\n",
    "\n",
    "def plot_vars_comparison_tpg(input_dir, output_dir, srv_list):\n",
    "    pcm_file, uprof_file, core_utilization_file, reformated_uprof_file, reformatter_core_utilization_file, all_file, all_plots_file = make_name_list(input_dir)\n",
    "    test_list = create_var_list(all_plots_file, tpg_test_list)\n",
    "    srv_file_list = create_var_list(all_plots_file, srv_list)\n",
    "    \n",
    "    X_plot_0 = []\n",
    "    Y_plot_0 = []\n",
    "    label_plot_0 = []\n",
    "    \n",
    "    for i in range(len(test_list)):\n",
    "        X_tmp = []\n",
    "        Y_tmp = []\n",
    "        label_tmp = []\n",
    "            \n",
    "        for file_i in test_list[i]:    \n",
    "            info = break_file_name(file_i)\n",
    "            data_frame = pd.read_csv('{}/{}.csv'.format(input_dir, file_i))\n",
    "            X_tmp.append(data_frame['NewTime'].values.tolist())\n",
    "\n",
    "            Y_tmp_0 = []\n",
    "            label_tmp_0 = []\n",
    "\n",
    "            if info[0]=='grafana':\n",
    "                for columns_pcm in columns_list_tpg[0]:\n",
    "                    Y_0, label_0 = get_column_val(data_frame, [columns_pcm], [label_columns[0]], file_i)  \n",
    "                    Y_tmp_0.append(Y_0)\n",
    "                    label_tmp_0.append(label_0)\n",
    "            else:\n",
    "                for columns_uprof in columns_list_tpg[1]:\n",
    "                    Y_0, label_0 = get_column_val(data_frame, [columns_uprof], [label_columns[0]], file_i)\n",
    "                    Y_tmp_0.append(Y_0)\n",
    "                    label_tmp_0.append(label_0)\n",
    "\n",
    "            Y_tmp.append(Y_tmp_0)\n",
    "            label_tmp.append(label_tmp_0)\n",
    "        \n",
    "        X_plot_0.append(X_tmp)\n",
    "        Y_plot_0.append(Y_tmp)\n",
    "        label_plot_0.append(label_tmp)\n",
    "    \n",
    "    X_plot_1 = []\n",
    "    Y_plot_1 = []\n",
    "    label_plot_1 = []\n",
    "    \n",
    "    for i in range(len(srv_file_list)):\n",
    "        X_tmp = []\n",
    "        Y_tmp = []\n",
    "        label_tmp = []\n",
    "            \n",
    "        for file_i in srv_file_list[i]:    \n",
    "            info = break_file_name(file_i)\n",
    "            data_frame = pd.read_csv('{}/{}.csv'.format(input_dir, file_i))\n",
    "            X_tmp.append(data_frame['NewTime'].values.tolist())\n",
    "\n",
    "            Y_tmp_1 = []\n",
    "            label_tmp_1 = []\n",
    "\n",
    "            if info[0]=='grafana':\n",
    "                for columns_pcm in columns_list_tpg[0]:\n",
    "                    Y_1, label_1 = get_column_val(data_frame, [columns_pcm], [label_columns[0]], file_i)  \n",
    "                    Y_tmp_1.append(Y_1)\n",
    "                    label_tmp_1.append(label_1)\n",
    "            else:\n",
    "                for columns_uprof in columns_list_tpg[1]:\n",
    "                    Y_1, label_1 = get_column_val(data_frame, [columns_uprof], [label_columns[0]], file_i)\n",
    "                    Y_tmp_1.append(Y_1)\n",
    "                    label_tmp_1.append(label_1)\n",
    "\n",
    "            Y_tmp.append(Y_tmp_1)\n",
    "            label_tmp.append(label_tmp_1)\n",
    "        \n",
    "        X_plot_1.append(X_tmp)\n",
    "        Y_plot_1.append(Y_tmp)\n",
    "        label_plot_1.append(label_tmp)\n",
    "    \n",
    "    # Here we make the plot:\n",
    "    matplotlib.rcParams['font.family'] = 'DejaVu Serif'\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 14))\n",
    "    plt.style.use('default')\n",
    "\n",
    "    for i in range(len(Y_plot_0)):  #number of tests\n",
    "        for j in range(len(Y_plot_0[i])):  #number of files\n",
    "            for k in range(len(Y_plot_0[i][j])):  #number of metrix\n",
    "                axs[i][k].plot(X_plot_0[i][j], Y_plot_0[i][j][k][0], color=color_list[j], label=label_plot_0[i][j][k][0], linestyle=linestyle_list[0])\n",
    "                axs[i][k].set_ylabel('{}'.format(label_names_tpg[k]))\n",
    "                axs[i][k].set_xlabel('Time (min)')\n",
    "                axs[i][k].grid(which='major', color='gray', linestyle='dashed')\n",
    "                axs[i][k].legend(loc='upper left')\n",
    "                \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{}/tpg_comparison_{}_{}_socket0.png'.format(output_dir, pdf_name, info[4]))\n",
    "    plt.close()\n",
    "    \n",
    "    fig, axs = plt.subplots(3, 2, figsize=(16, 14))\n",
    "    plt.style.use('default')\n",
    "    \n",
    "    for i in range(len(Y_plot_1)):  #number of tests\n",
    "        for j in range(len(Y_plot_1[i])):  #number of files\n",
    "            for k in range(len(Y_plot_1[i][j])):  #number of metrix\n",
    "                axs[i][k].plot(X_plot_1[i][j], Y_plot_1[i][j][k][0], color=color_list[j], label=label_plot_1[i][j][k][0], linestyle=linestyle_list[0])\n",
    "                axs[i][k].set_ylabel('{}'.format(label_names_tpg[k]))\n",
    "                axs[i][k].set_xlabel('Time (min)')\n",
    "                axs[i][k].grid(which='major', color='gray', linestyle='dashed')\n",
    "                axs[i][k].legend(loc='upper left')\n",
    "                \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{}/tpg_comparison_{}_{}_socket0_srvs.png'.format(output_dir, pdf_name, info[4]))\n",
    "    plt.close()\n",
    "\n",
    "def create_report_tpg_standalone(input_dir, output_dir, daqconfs_cpupins_folder_parent_dir, srv_list, process_pcm_files=False, process_uprof_files=False, streams='48', pdf_name='tpgs_standalon_report', repin_threads_file=None, comment=['TBA']):    \n",
    "    directory([input_dir, output_dir])\n",
    "    now = dt.now()\n",
    "    current_dnt = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    pcm_file, uprof_file, core_utilization_file, reformated_uprof_file, reformatter_core_utilization_file, all_file, all_plots_file = make_name_list(input_dir)\n",
    "    \n",
    "    # Open pdf file\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.ln(1)\n",
    "    pdf.image('{}/tools/dune_logo_3.jpg'.format(performancetest_path), w=180)\n",
    "    pdf.ln(2)\n",
    "    pdf.set_font('Times', 'B', 16)\n",
    "    pdf.cell(40,10,'TPG Standalone Report')\n",
    "    pdf.write(5,'\\n\\n')\n",
    "    \n",
    "    # Processing the data first\n",
    "    if process_pcm_files:\n",
    "        for i, file_pcm_i in enumerate(pcm_file):\n",
    "            add_new_time_format(input_dir, file_pcm_i)\n",
    "\n",
    "    if process_uprof_files:\n",
    "        for i, file_uprof_i in enumerate(uprof_file):\n",
    "            uprof_pcm_formatter(input_dir, file_uprof_i)\n",
    "            add_new_time_format(input_dir, 'reformatter_{}'.format(file_uprof_i))\n",
    "    \n",
    "    cpupins_utilazation_reformatter(input_dir)\n",
    "    for i, file_core_i in enumerate(core_utilization_file):\n",
    "         add_new_time_format_utilization(input_dir, 'reformatter_{}'.format(file_core_i))\n",
    "        \n",
    "    if process_pcm_files or process_uprof_files:\n",
    "        print('Finish the processing of the data.')\n",
    "    \n",
    "    info_pcm_basic = break_file_name(all_file[0])\n",
    "    \n",
    "    # creating report\n",
    "    pdf.set_font('Times', '', 10)\n",
    "    pdf.write(5, 'The tests were run for the WIB{} data format for {} streams. The Figures 1 and 2 show the results of the tests ran (Table1) using the different metrics. \\n'.format(info_pcm_basic[4], streams))\n",
    "    pdf.write(5,'\\n')\n",
    "    #-------------------------------------------TABLE-----------------------------------------------\n",
    "    # Data to tabular\n",
    "    rows_data = []\n",
    "    headers = ['Test', 'Readout SRV', 'dunedaq', 'OS', 'NODE', 'General comments']\n",
    "    rows_data.append(headers)\n",
    "    \n",
    "    line_height = pdf.font_size * 2\n",
    "    col_width = [pdf.epw/3.8, pdf.epw/8, pdf.epw/12, pdf.epw/12, pdf.epw/12, pdf.epw/3.5]  \n",
    "    lh_list = [] #list with proper line_height for each row\n",
    "    \n",
    "    for i, file_i in enumerate(all_file):\n",
    "        info = break_file_name(file_i)\n",
    "        test_info = re.sub('_', ' ', info[5])\n",
    "        line = [test_info, info[2], info[1], check_OS(info[2]), info[3], comment[i]]\n",
    "        rows_data.append(line)\n",
    "    \n",
    "    # Determine line heights based on the number of words in each cell\n",
    "    for row in rows_data:\n",
    "        max_lines = 1  # Initialize with a minimum of 1 line\n",
    "        for datum in row:\n",
    "            lines_needed = len(str(datum).split('\\n'))  # Count the number of lines\n",
    "            max_lines = max(max_lines, lines_needed)\n",
    " \n",
    "        lh_list.append(line_height * max_lines)\n",
    "        \n",
    "    # Add table rows with word wrapping and dynamic line heights\n",
    "    for j, row in enumerate(rows_data):\n",
    "        line_height_table = lh_list[j] \n",
    "        for k, datum in enumerate(row):\n",
    "            pdf.multi_cell(col_width[k], line_height_table, datum, border=1, align='L', new_x=XPos.RIGHT, new_y=YPos.TOP, max_line_height=pdf.font_size)\n",
    "            \n",
    "        pdf.ln(line_height_table)\n",
    "        \n",
    "    pdf.write(5, 'Table 1. Summary of the tests ran. \\n')    \n",
    "    pdf.ln(10)\n",
    "    \n",
    "    #--------------------------------------------FIGURES------------------------------------------------\n",
    "    plot_vars_comparison(input_dir, output_dir, pdf_name)\n",
    "    \n",
    "    if info[3] == '0' or info[3] == '01':\n",
    "        pdf.image('{}/tpg_comparison_{}_{}_socket0.png'.format(output_dir, pdf_name, info_pcm_basic[4]), w=180)\n",
    "        pdf.write(5, 'Figure 1. Socket0 comparison of the tests ran for different servers using the metrics \"Instructions Per Cycle\" and \"Instructions Retired Any\".')\n",
    "        pdf.ln(10)\n",
    "        pdf.image('{}/tpg_comparison_{}_{}_socket0_srvs.png'.format(output_dir, pdf_name, info_pcm_basic[4]), w=180)\n",
    "        pdf.write(5, 'Figure 2. Socket0 Figure2. Socket0 comparison of the tests ran per servers using the metrics \"Instructions Per Cycle\" and \"Instructions Retired Any\".')\n",
    "        pdf.ln(10)\n",
    "        \n",
    "        if info[3] == '01':\n",
    "            pdf.image('{}/tpg_comparison_{}_{}_socket0.png'.format(output_dir, pdf_name, info_pcm_basic[4]), w=180)\n",
    "            pdf.write(5, 'Figure 3. Socket1 comparison of the tests ran for different servers using the metrics \"Instructions Per Cycle\" and \"Instructions Retired Any\".')\n",
    "            pdf.ln(10)\n",
    "            pdf.image('{}/tpg_comparison_{}_{}_socket0_srvs.png'.format(output_dir, pdf_name, info_pcm_basic[4]), w=180)\n",
    "            pdf.write(5, 'Figure 4. Socket1 Figure2. Socket0 comparison of the tests ran per servers using the metrics \"Instructions Per Cycle\" and \"Instructions Retired Any\".')\n",
    "            pdf.ln(10)\n",
    "        \n",
    "    if info[3] == '1':\n",
    "        pdf.image('{}/tpg_comparison_{}_{}_socket0.png'.format(output_dir, pdf_name, info_pcm_basic[4]), w=180)\n",
    "        pdf.write(5, 'Figure 1. Socket1 comparison of the tests ran for different servers using the metrics \"Instructions Per Cycle\" and \"Instructions Retired Any\".')\n",
    "        pdf.ln(10)\n",
    "        pdf.image('{}/tpg_comparison_{}_{}_socket0_srvs.png'.format(output_dir, pdf_name, info_pcm_basic[4]), w=180)\n",
    "        pdf.write(5, 'Figure 2. Socket1 Figure2. Socket0 comparison of the tests ran per servers using the metrics \"Instructions Per Cycle\" and \"Instructions Retired Any\".')\n",
    "        pdf.ln(10)\n",
    "        \n",
    "    #----------------------------------------CONFIGURATIONS---------------------------------------------\n",
    "    pcm_file, uprof_file, core_utilization_file, reformated_uprof_file, reformated_core_utilization_file, all_file, all_plots_file = make_name_list(input_dir)\n",
    "    \n",
    "    if print_info:\n",
    "        pdf.write(5, 'Configurations: \\n', 'B')\n",
    "        for i in range(len(all_file)):\n",
    "            info = break_file_name(all_file[i])\n",
    "            \n",
    "            var_i='ru{}{}{}'.format(info[2], info[4], '0')\n",
    "            file_daqconf_i='daqconf-{}-{}-{}-{}'.format(info[4], info[5], info[2], info[3])\n",
    "            file_core_i='reformatter_core_utilization-{}-{}-{}-{}-{}'.format(info[1], info[2], info[3], info[4], info[5])\n",
    "            \n",
    "            if os.path.exists('{}/{}'.format(input_dir,file_core_i)):\n",
    "                json_info(file_daqconf=file_daqconf_i, file_core=file_core_i, input_directory=daqconfs_cpupins_folder_parent_dir, input_dir=input_dir, var=var_i, pdf=pdf, if_pdf=print_info, repin_threads_file=repin_threads_file)\n",
    "            else:\n",
    "                print('Missing {}'.format(file_core_i))\n",
    "                json_info(file_daqconf=file_daqconf_i, file_core='reformatter_core_utilization-all0', input_directory=daqconfs_cpupins_folder_parent_dir, input_dir='{}/tools'.format(daqconfs_cpupins_folder_parent_dir), var=var_i, pdf=pdf, if_pdf=print_info, repin_threads_file=repin_threads_file)\n",
    "            \n",
    "            pdf.cell(0, 10, 'Table {}. CPU core pins information for the \"{}\" test using dune_daq {}.'.format(i+2, info[5], info[1]))\n",
    "            pdf.ln(10)           \n",
    "            \n",
    "    pdf.ln(20)\n",
    "    pdf.set_font('Times', '', 10)\n",
    "    pdf.write(5, 'The End, made on {}'.format(current_time()))\n",
    "    pdf.output('{}/{}_report.pdf'.format(output_dir, pdf_name))\n",
    "    \n",
    "print('Ready to run and process')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578984c4",
   "metadata": {},
   "source": [
    "# Proccesing data from Grafana\n",
    "Note: change the paths to fit yours\n",
    "\n",
    "To extract the data from a given dashboard in grafana:\n",
    "* 'grafana_url' is:\n",
    "    * 'http://np04-srv-009.cern.ch:3000'  (legacy)\n",
    "    * 'http://np04-srv-017.cern.ch:31023' (new) \n",
    "* 'dashboard_uid' is the unic dashboard identifiyer, you can find this information on the link of the dashboard. The dashboard_uid code is in the web link after/d/.../ \n",
    "    * for intel-r-performance-counter-monitor-intel-r-pcm dashboard dashboard_uid = '91zWmJEVk' \n",
    "* delta_time is [start, end] given in the format '%Y-%m-%d %H:%M:%S'\n",
    "* host is the name of the server in study for example: \"np02-srv-003\"     \n",
    "\n",
    "file_name (for tpgs standalon tests): NFD-[server_app_tested]-[numa node]-[data format]-[tests_name]\n",
    "* example of name: NFD-np04srv025-0-eth-tpg_SimpletTreshold_standalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grafana_url = 'http://np04-srv-017.cern.ch:31023'\n",
    "dashboard_uid = ['91zWmJEVk']\n",
    "host_used = ['np04-srv-028','np02-srv-002','np04-srv-025']\n",
    "\n",
    "delta_time0 = [['2023-10-03 12:02:52', '2023-10-03 12:04:46'], ['2023-10-03 12:06:49', '2023-10-03 12:08:43']]\n",
    "delta_time1 = [['2023-10-03 12:17:55', '2023-10-03 12:19:50'], ['2023-10-03 12:21:52', '2023-10-03 12:23:45']]\n",
    "delta_time2 = [['2023-10-03 12:10:27', '2023-10-03 12:12:20'], ['2023-10-03 12:13:54', '2023-10-03 12:15:47']]       \n",
    "delta_time = [delta_time0, delta_time1, delta_time2]\n",
    "\n",
    "output_csv_file0 = ['NFD-np04srv028-0-eth-tpg_SimpletTreshold_standalone', 'NFD-np04srv028-0-eth-tpg_AbsRS_standalone']\n",
    "output_csv_file1 = ['NFD-np02srv002-0-eth-tpg_SimpletTreshold_standalone', 'NFD-np02srv002-0-eth-tpg_AbsRS_standalone']\n",
    "output_csv_file2 = ['NFD-np04srv025-0-eth-tpg_SimpletTreshold_standalone', 'NFD-np04srv025-0-eth-tpg_AbsRS_standalone']\n",
    "output_csv_file = [output_csv_file0, output_csv_file1, output_csv_file2]\n",
    "\n",
    "results_path = '/eos/home-d/dvargas/SWAN_projects/adam_test'\n",
    "\n",
    "for host_i, delta_time_i, output_csv_file_i in zip(host_used, delta_time, output_csv_file):\n",
    "    for delta_time_list, output_csv_file_list in zip(delta_time_i, output_csv_file_i):\n",
    "        extract_data_and_stats_from_panel(grafana_url, dashboard_uid, delta_time=delta_time_list, \n",
    "                                          host=host_i, input_dir=results_path, \n",
    "                                          output_csv_file=output_csv_file_list)\n",
    "\n",
    "print('done :-)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60327afa",
   "metadata": {},
   "source": [
    "# TPG standalone performance report\n",
    "Note: change the paths to fit yours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = '/eos/home-d/dvargas/SWAN_projects/adam_test'\n",
    "report_path = '/eos/home-d/dvargas/SWAN_projects/reports'\n",
    "host_list = ['np04srv028','np02srv002','np04srv025']\n",
    "\n",
    "create_report_tpg_standalone(input_dir=results_path, output_dir=report_path, srv_list=host_list, \n",
    "                             process_pcm_files=False, process_uprof_files=False, \n",
    "                             pdf_name='tpg_standalone_report')\n",
    "print('THE END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b17422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
