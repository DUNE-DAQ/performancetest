{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad15bb0",
   "metadata": {},
   "source": [
    "# Import the modules needed, defining paths, and funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d8e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from basic_functions import *\n",
    "\n",
    "print('Cheking list od packages need it')\n",
    "for package_i in list_py_package:\n",
    "    debug_missing_module(module_name=package_i)\n",
    "\n",
    "def phoronix_benchmark_reader(file):\n",
    "    filename = file.split('/')[-1][:-4]\n",
    "    pattern_text = r'Flexible IO Tester - Type: (?P<type>.+) - Engine: (?P<engine>.+) - Buffered: (?P<buffered>.+) - Direct: (?P<direct>.+) - Block Size: (?P<block_size>.+)KB - Disk Target: (?P<disk_target>.+) .MB.s.'\n",
    "    pattern_fio = re.compile(pattern_text)\n",
    "\n",
    "    pattern_text = r'Stream - Type: (?P<type>.+) .MB.s.'\n",
    "    pattern_stream = re.compile(pattern_text)\n",
    "\n",
    "    fio_data = []\n",
    "    stream_data = []\n",
    "    header = []\n",
    "    whitespace_counter = 0\n",
    "\n",
    "    with open(file) as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for i,row in enumerate(reader):\n",
    "            if (i==0):\n",
    "                header.append('======================================== '+ filename + ' ========================================')\n",
    "            elif row==[]:\n",
    "                whitespace_counter += 1\n",
    "                if whitespace_counter<3:\n",
    "                    header.append('  '.join(row))\n",
    "                else:\n",
    "                    break\n",
    "            elif whitespace_counter<2:\n",
    "                header.append('  '.join(row))\n",
    "            elif pattern_fio.match(row[0]):\n",
    "                header_end = True\n",
    "                groups = pattern_fio.match(row[0]).groupdict()\n",
    "                groups['result'] = row[2]\n",
    "                fio_data.append(groups)\n",
    "            elif pattern_stream.match(row[0]):\n",
    "                header_end = True\n",
    "                groups = pattern_stream.match(row[0]).groupdict()\n",
    "                groups['result'] = row[2]\n",
    "                stream_data.append(groups)\n",
    "            \n",
    "\n",
    "    fio_df = pd.DataFrame(fio_data)\n",
    "    stream_df = pd.DataFrame(stream_data)\n",
    "    stream_df['result'] = stream_df['result'].astype('float')\n",
    "    \n",
    "    return fio_df, stream_df, header\n",
    "\n",
    "def phoronix_benchmark_plotter(fio_df, stream_df, header, output_dir):\n",
    "\n",
    "    fio_df['block_size'] = fio_df['block_size'].astype('int')\n",
    "    fio_df['result'] = fio_df['result'].astype('float')\n",
    "    \n",
    "    type_list = fio_df.type.unique()\n",
    "    target_list = fio_df.disk_target.unique()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20,4))\n",
    "    plt.style.use('default')\n",
    "    \n",
    "    for i, test in enumerate(type_list):\n",
    "        for target in target_list:\n",
    "            df_test_i = fio_df[(fio_df.type == test) & (fio_df.disk_target == target)]\n",
    "            axs[i].plot(df_test_i.block_size, df_test_i.result, label=target)\n",
    "        \n",
    "        axs[i].set_title('Flexible IO Tester - ' + test)\n",
    "        if i == 0:    \n",
    "            axs[i].set_ylabel('IO speed (MB/s)')\n",
    "        axs[i].set_xlabel('block size (KB)')\n",
    "        axs[i].grid()\n",
    "\n",
    "    plt.savefig('{}/fio_plots.png'.format(output_dir))\n",
    "    plt.close()\n",
    "\n",
    "def report_test_options(df, pdf):\n",
    "    pdf.write(5,'Options: \\n')\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if column == 'result':\n",
    "            pass\n",
    "        else:\n",
    "            unique = df[column].unique()\n",
    "            pdf.write(5, column)\n",
    "            pdf.write(5, ': ')\n",
    "            pdf.write(5, ', '.join(unique))\n",
    "            pdf.write(5, '\\n')\n",
    "    pdf.write(5,'\\n')\n",
    "\n",
    "def create_report_benchmark(input_dir, output_dir):\n",
    "    directory([input_dir, output_dir])\n",
    "    \n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font('Arial', 'B', 16)\n",
    "    pdf.cell(40,10,'Benchmark Report')\n",
    "    pdf.write(5,'\\n\\n')\n",
    "    \n",
    "    benchmark_list = make_name_list_benchmark(input_dir)\n",
    "\n",
    "    for pag, file_list in enumerate(benchmark_list):\n",
    "\n",
    "        fio_df, stream_df, header = phoronix_benchmark_reader(file='{}/{}.csv'.format(input_dir, file_list))\n",
    "        phoronix_benchmark_plotter(fio_df.copy(), stream_df, header, output_dir)\n",
    "        \n",
    "        pdf.set_font('Arial', '', 8)\n",
    "        for line in header:\n",
    "            pdf.write(5, line)\n",
    "            pdf.write(5,'\\n')\n",
    "        \n",
    "        test_suite = 'dunedaq-srv-benchmark'\n",
    "        pdf.write(5, 'Test suite name: {} \\n'.format(test_suite))\n",
    "        pdf.write(5, 'Suite definition and test versions here: performancetest/benchmark/local/{}/suite-definition.xml \\n\\n'.format(test_suite))\n",
    "        \n",
    "        pdf.set_font('Arial', 'B', 8)\n",
    "        pdf.write(5, 'Flexible IO Tester')\n",
    "        pdf.set_font('Arial', '', 8)\n",
    "        pdf.write(5,' - tests read/write speed to RAID storage for SNB recording \\n')\n",
    "        report_test_options(fio_df, pdf)\n",
    "        pdf.image('{}/fio_plots.png'.format(output_dir), w=200)\n",
    "        pdf.write(5,'\\n\\n')\n",
    "        \n",
    "        pdf.set_font('Arial', 'B', 8)\n",
    "        pdf.write(5, 'STREAM')\n",
    "        pdf.set_font('Arial', '', 8)\n",
    "        pdf.write(5, ' - tests CPU memory bandwidth in MB/s using 4 operation types \\n')\n",
    "        report_test_options(stream_df, pdf)\n",
    "        pdf.write(5, stream_df.to_string())\n",
    "        pdf.write(5,'\\n\\n')\n",
    "        pdf.write(5, 'Average CPU memory bandwidth: {} MB/s \\n'.format(float(stream_df.mean(numeric_only=True))))\n",
    "        \n",
    "        if pag+1 == len(benchmark_list):\n",
    "            pass\n",
    "        else:\n",
    "            pdf.add_page()\n",
    "\n",
    "    pdf.write(5,'\\n\\n')\n",
    "    pdf.write(5,'The End, made on {}'.format(current_time()))\n",
    "    pdf.output('{}/benchmark_report.pdf'.format(output_dir))\n",
    "    \n",
    "print('Ready to run and process')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97494a",
   "metadata": {},
   "source": [
    "# Benchmark report\n",
    "Note: change the paths to fit yours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58834f22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Phoronix data \n",
    "benchmark_path = '../benckmark_results'\n",
    "report_path = '../reports'\n",
    "\n",
    "create_report_benchmark(benchmark_path, report_path)\n",
    "\n",
    "print('THE END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e86fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
